Runs in Coin Flips: Instructor's Notes
========================================================

```{r warnings=FALSE,errors=FALSE,message=FALSE,results="hide",echo=FALSE}
require(mosaic)
```

## Background 

Description:
An introduction to patterns in randomness.  In this case, the pattern is runs of heads and tails in coin flips.  These constitute a kind of "statistical fingerprint" which can be detected with the right tools.

Requirements:
* RStudio (for the manipulate functionality)
* The `mosaic` package
* Sourcing `enterCoins.R` through the `fetchData()` command below in the mosaic package.

## Introduction

We're going to do a demonstration that will show you a bit of statistical logic.  The point is to show that's it's possible to detect the traces of human involvement in a supposedly random sequence.  

Divide into groups of two or more students.  One student in the group will work the computer, entering data.  Another student will generate the data.

The student generating the data will either flip a coin repeatedly or will make up a random-looking sequence of heads and tails without actually flipping the coin.  We're going to try to detect when the process is real flipping and when it's not.

### Data Entry

Start up RStudio, and give the following commands:
```{r results="hide", message=FALSE}
require(mosaic)
fetchData("enterCoins.R")
```

From the command line, give this command:
```{r eval=FALSE}
enter.coins(n=10)
```
Then, referring to the "Plot" window, press the "H" and "T" buttons ten times to enter a string of simulated coin flips.  (If no menu pops up, click on the little gear icon in the plot window.)

Then give this command to confirm that the coins have been entered:
```{r eval=FALSE}
coin.history
```

Practice this until you feel comfortable.  It isn't hard.  Each time you restart `enter.coins()` you will be erasing your old history.

### The Group

Pick two people in the group and play the oddsies/evensies finger game.  If your result is odd, then you will be flipping a genuine coin.  If your result is even, then you will be making up coin flips.

The data entry person should give the command
```{r eval=FALSE}
enter.coins(n=50)
```
to enter 50 coin flips worth of data.

Another person in the group ``generate'' the coin flips, either legitimately or made up, per the previous paragraph.  (If you have more than two people in your group, the non-data entry people might want to alternate in generating the made-up coin flips.) The data entry person should enter the data.

### The Magic

Once the data are entered, go back to the R console and give this command:
```{r eval=FALSE}
test.coins( coin.history )
```

Did the `test.coins()` function get it right?

## Discussion

* How do you think `test.coins()` did it?  What patterns might it look for?

* We can test the ``specificity'' of the test by generating a genuinely random sequence and seeing how often the test correctly identifies the sequence as random.
```{r}
do(10) * test.coins( resample( c("H","T"), size=100))
```

* Another quantity, called the ``sensitivity," quantifies how often the test correctly identifies the sequence as not from a random coin.  To do this, you need to be able to state what ``not a random coin" means.  For instance, here's a process that tends to put tails after heads and vice versa. (This code is very obscure.)
```{r}
do(10) * test.coins( unlist(resample( list(c("H", "T"), c("T", "H"), "H", "T"), size=100))[1:100])
```

By changing the size of the sequence --- it's 100 in the above examples --- you can change the sensitivity and specificity of the test.  Ideally, the test will always get it right.

* How short a test will get things right about 90% of the time?

* How long a test is needed to get things right 99% of the time?

