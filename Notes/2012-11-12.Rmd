Stats 155 Class Notes 2012-11-12
================================

```{r name="setup", child="notes-setup.Rmd"}
# boilerplate
```

```{r include=FALSE}
require(xtable,quietly=TRUE)
```

### Grading the Election Model predictions

Hand out random papers with prediction models and direct students to [this app for evaluating your election result model](http://glimmer.rstudio.com/mosaic/Election2012/).  Adjust the parameters as indicated and write the resulting likelihood on the top of the paper.

See who has the largest likelihood in the class.

Suppose you were trying to decide between two hypotheses based on the data.  Here's how:

p( mod1 | 332) = p(332|mod1)p(mod1)/p(332)

What's p(332)?  Since either mod1 or mod2 is right (by your prior) then
p(332) = p(332|mod1)p(mod1) + p(332|mod2)p(mod2)

More simply, assign model a value of p(332|modX) p(modX).  The posterior probability p(modX|332) is simply the value p(332|modX)p(modX) divided by the sum of the similar term.

If the priors are all the same, then the posterior probability is proportional to the likelihood.


ANOVA
-------------

### The elementary setting for ANOVA

Differences among groups.  When there are two groups, this is called a "t-test".  More than two, it's traditionally called simply "ANOVA" or "one-way ANOVA", but it's just a standard application of the ANOVA procedure to a simple model.

#### The t-test

Consider the difference between the sexes in wage:
```{r}
mod = lm( wage ~ sex, data=CPS85 )
summary(mod)
anova(mod)
```
Note that the regression report and the ANOVA report give the same p-value.  There's no "team" issue when there is just one coefficient at issue.

For multiple groups, consider wage versus sector:
```{r}
mod2 = lm( wage ~ sector, data=CPS85 )
summary(mod2)
```
In the regression report, each sector gets its own p-value with respect to the reference sector.  It might be that there is not enough evidence to support a claim that any given sector is different from the reference, but taken together they suggest that the overall variable is playing a role in explaining the response variable.  ANOVA provides a simple way to combine the contributions of all the levels of the variable.
```{r}
anova(mod2)
```

In the **Null Hypothesis** world, the "explanatory" variables are no better than the residuals.  Here's how that shows up in the ANOVA table
```{r}
modnull = lm( wage ~ shuffle(sector), data=CPS85 )
anova(modnull)
```

